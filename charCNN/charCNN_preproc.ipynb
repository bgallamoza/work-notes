{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              title  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "data = './data/ag_news_csv/train.csv'\n",
    "\n",
    "train_df = pd.read_csv(data, header=None, names=['class', 'title', 'description'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate column 1 and 2 as one text\n",
    "train_df['text'] = train_df.title + train_df.description\n",
    "train_df.drop(['title', 'description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reute...\n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...\n",
       "2      3  Oil and Economy Cloud Stocks' Outlook (Reuters...\n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...\n",
       "4      3  Oil prices soar to all-time record, posing new..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of texts: 120000\n",
      "First two text excerpts:\n",
      "[\"wall st. bears claw back into the black (reuters)reuters - short-sellers, wall street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'carlyle looks toward commercial aerospace (reuters)reuters - private investment firm carlyle group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.']\n"
     ]
    }
   ],
   "source": [
    "texts = train_df.text.values # text values as an array\n",
    "texts = [ s.lower() for s in texts ] # preproc texts to all lowercase to match vocab\n",
    "\n",
    "print(f\"Length of texts: {len(texts)}\")\n",
    "print(f\"First two text excerpts:\\n{texts[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 1,\n",
       " ' ': 2,\n",
       " 'e': 3,\n",
       " 'a': 4,\n",
       " 't': 5,\n",
       " 'i': 6,\n",
       " 's': 7,\n",
       " 'o': 8,\n",
       " 'n': 9,\n",
       " 'r': 10,\n",
       " 'l': 11,\n",
       " 'd': 12,\n",
       " 'h': 13,\n",
       " 'c': 14,\n",
       " 'u': 15,\n",
       " 'p': 16,\n",
       " 'm': 17,\n",
       " 'g': 18,\n",
       " 'f': 19,\n",
       " 'y': 20,\n",
       " 'w': 21,\n",
       " 'b': 22,\n",
       " '.': 23,\n",
       " 'v': 24,\n",
       " 'k': 25,\n",
       " ',': 26,\n",
       " '-': 27,\n",
       " ';': 28,\n",
       " '3': 29,\n",
       " '0': 30,\n",
       " 'x': 31,\n",
       " '9': 32,\n",
       " 'j': 33,\n",
       " 'q': 34,\n",
       " '#': 35,\n",
       " '1': 36,\n",
       " '(': 37,\n",
       " ')': 38,\n",
       " '2': 39,\n",
       " \"'\": 40,\n",
       " 'z': 41,\n",
       " '\\\\': 42,\n",
       " '&': 43,\n",
       " ':': 44,\n",
       " '/': 45,\n",
       " '5': 46,\n",
       " '4': 47,\n",
       " '6': 48,\n",
       " '\"': 49,\n",
       " '7': 50,\n",
       " '$': 51,\n",
       " '8': 52,\n",
       " '=': 53,\n",
       " '?': 54,\n",
       " '!': 55,\n",
       " '_': 56,\n",
       " '*': 57}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train Tokenizer on text\n",
    "# The Tokenizer at a character level will detect all unique characters that exist on the training dataset (texts)\n",
    "# When not at char_level, it does this on all unique words\n",
    "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
    "tk.fit_on_texts(texts)\n",
    "\n",
    "# This generates a character dictionary learned from the training data\n",
    "tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '0': 27,\n",
       " '1': 28,\n",
       " '2': 29,\n",
       " '3': 30,\n",
       " '4': 31,\n",
       " '5': 32,\n",
       " '6': 33,\n",
       " '7': 34,\n",
       " '8': 35,\n",
       " '9': 36,\n",
       " '-': 60,\n",
       " ',': 38,\n",
       " ';': 39,\n",
       " '.': 40,\n",
       " '!': 41,\n",
       " '?': 42,\n",
       " ':': 43,\n",
       " \"'\": 44,\n",
       " '\"': 45,\n",
       " '/': 46,\n",
       " '\\\\': 47,\n",
       " '|': 48,\n",
       " '_': 49,\n",
       " '@': 50,\n",
       " '#': 51,\n",
       " '$': 52,\n",
       " '%': 53,\n",
       " '^': 54,\n",
       " '&': 55,\n",
       " '*': 56,\n",
       " '~': 57,\n",
       " '`': 58,\n",
       " '+': 59,\n",
       " '=': 61,\n",
       " '<': 62,\n",
       " '>': 63,\n",
       " '(': 64,\n",
       " ')': 65,\n",
       " '[': 66,\n",
       " ']': 67,\n",
       " '{': 68,\n",
       " '}': 69}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Although we generated a vocabulary already, we already have an existing character list:\n",
    "alphabet=\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "char_dict = {}\n",
    "for i, char in enumerate(alphabet):\n",
    "    char_dict[char] = i + 1\n",
    "    \n",
    "char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we just need to add the 'UNK' character to the vocabulary\n",
    "\n",
    "tk.word_index = char_dict   # assign Tokenizer's word index to our custom index\n",
    "tk.word_index[tk.oov_token] = max(char_dict.values()) + 1   # append 'UNK' to be the next sequential value of the char dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Characters to Index\n",
    "\n",
    "In this step, the goal is to represent all text by using its character index according to the char_dict we set earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall st. bears claw back into the black (reuters)reuters - short-sellers, wall street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "[23, 1, 12, 12, 70, 19, 20, 40, 70, 2, 5, 1, 18, 19, 70, 3, 12, 1, 23, 70, 2, 1, 3, 11, 70, 9, 14, 20, 15, 70, 20, 8, 5, 70, 2, 12, 1, 3, 11, 70, 64, 18, 5, 21, 20, 5, 18, 19, 65, 18, 5, 21, 20, 5, 18, 19, 70, 60, 70, 19, 8, 15, 18, 20, 60, 19, 5, 12, 12, 5, 18, 19, 38, 70, 23, 1, 12, 12, 70, 19, 20, 18, 5, 5, 20, 44, 19, 70, 4, 23, 9, 14, 4, 12, 9, 14, 7, 47, 2, 1, 14, 4, 70, 15, 6, 70, 21, 12, 20, 18, 1, 60, 3, 25, 14, 9, 3, 19, 38, 70, 1, 18, 5, 70, 19, 5, 5, 9, 14, 7, 70, 7, 18, 5, 5, 14, 70, 1, 7, 1, 9, 14, 40]\n"
     ]
    }
   ],
   "source": [
    "# This can be accomplished using tk.texts_to_sequences()\n",
    "sequences = tk.texts_to_sequences(texts)\n",
    "\n",
    "# notice how a string has been converted to a character array, where each value is the char_dict\n",
    "# value corresponding to that character key\n",
    "print(texts[0])\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "As you might imagine, all the texts have different lengths, and they must be normalized so that the CNN can handle the batch data. Notice that our `char_dict` starts at 1, not 0. This is because 0 will serve as our meaningless padding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(\n",
    "    sequences,                                  # sequences to be padded\n",
    "    maxlen=max([len(i) for i in sequences]),    # get max length of all sequences\n",
    "    padding='post'                              # pad sequences on the right end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 1, 12, 12, 70, 19, 20, 40, 70, 2, 5, 1, 18, 19, 70, 3, 12, 1, 23, 70, 2, 1, 3, 11, 70, 9, 14, 20, 15, 70, 20, 8, 5, 70, 2, 12, 1, 3, 11, 70, 64, 18, 5, 21, 20, 5, 18, 19, 65, 18, 5, 21, 20, 5, 18, 19, 70, 60, 70, 19, 8, 15, 18, 20, 60, 19, 5, 12, 12, 5, 18, 19, 38, 70, 23, 1, 12, 12, 70, 19, 20, 18, 5, 5, 20, 44, 19, 70, 4, 23, 9, 14, 4, 12, 9, 14, 7, 47, 2, 1, 14, 4, 70, 15, 6, 70, 21, 12, 20, 18, 1, 60, 3, 25, 14, 9, 3, 19, 38, 70, 1, 18, 5, 70, 19, 5, 5, 9, 14, 7, 70, 7, 18, 5, 5, 14, 70, 1, 7, 1, 9, 14, 40] \n",
      "\n",
      "[23  1 12 12 70 19 20 40 70  2  5  1 18 19 70  3 12  1 23 70  2  1  3 11\n",
      " 70  9 14 20 15 70 20  8  5 70  2 12  1  3 11 70 64 18  5 21 20  5 18 19\n",
      " 65 18  5 21 20  5 18 19 70 60 70 19  8 15 18 20 60 19  5 12 12  5 18 19\n",
      " 38 70 23  1 12 12 70 19 20 18  5  5 20 44 19 70  4 23  9 14  4 12  9 14\n",
      "  7 47  2  1 14  4 70 15  6 70 21 12 20 18  1 60  3 25 14  9  3 19 38 70\n",
      "  1 18  5 70 19  5  5  9 14  7 70  7 18  5  5 14 70  1  7  1  9 14 40  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(sequences[0][:160], \"\\n\")\n",
    "print(data[0][:160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 1011)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that our data has been normalized, we can convert the 2D list to a numpy array\n",
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the Labels\n",
    "\n",
    "In this step, we're going to make our labels begin as 0-index (since they start with 1, currently). Afterwards, because this is a multiclass classifier task, we need the classes to be one-hot encoded. There are 4 classes, so 4 class columns will be created; a column value will be 1 if that column matches that sample's class, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [ x-1 for x in train_df['class'].values ]    # make classes start with 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "classes = to_categorical(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 3, 3]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list[75:80]   # note the classes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[75:80]  # now note where the 1 value is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>1</td>\n",
       "      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>2</td>\n",
       "      <td>Renteria signing a top-shelf dealRed Sox gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>2</td>\n",
       "      <td>Saban not going to Dolphins yetThe Miami Dolph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>2</td>\n",
       "      <td>Today's NFL gamesPITTSBURGH at NY GIANTS Time:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2</td>\n",
       "      <td>Nets get Carter from RaptorsINDIANAPOLIS -- Al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                                               text\n",
       "0           3  Wall St. Bears Claw Back Into the Black (Reute...\n",
       "1           3  Carlyle Looks Toward Commercial Aerospace (Reu...\n",
       "2           3  Oil and Economy Cloud Stocks' Outlook (Reuters...\n",
       "3           3  Iraq Halts Oil Exports from Main Southern Pipe...\n",
       "4           3  Oil prices soar to all-time record, posing new...\n",
       "...       ...                                                ...\n",
       "119995      1  Pakistan's Musharraf Says Won't Quit as Army C...\n",
       "119996      2  Renteria signing a top-shelf dealRed Sox gener...\n",
       "119997      2  Saban not going to Dolphins yetThe Miami Dolph...\n",
       "119998      2  Today's NFL gamesPITTSBURGH at NY GIANTS Time:...\n",
       "119999      2  Nets get Carter from RaptorsINDIANAPOLIS -- Al...\n",
       "\n",
       "[120000 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to skip preprocessing stuff\n",
    "from utils.preprocess import preprocess_text\n",
    "\n",
    "train_data, train_classes, test_data, test_classes, tk = preprocess_text(\n",
    "    train_path='./data/ag_news_csv/train.csv',\n",
    "    test_path='./data/ag_news_csv/test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tk.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = []\n",
    "embedding_weights.append(np.zeros(vocab_size))  # we create a zero vector to represent the padding value\n",
    "\n",
    "# for each character, generate a sparse array of zeros where a value of 1 is given for the index of that character\n",
    "for char, idx in tk.word_index.items():\n",
    "    onehot = np.zeros(vocab_size)\n",
    "    onehot[idx-1] = 1\n",
    "    embedding_weights.append(onehot)\n",
    "\n",
    "embedding_weights = np.array(embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 69)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer initialization\n",
    "\n",
    "input_size = 1014\n",
    "# vocab_size = 69\n",
    "embedding_size = 69\n",
    "conv_layers = [\n",
    "    [256, 7, 3],\n",
    "    [256, 7, 3],\n",
    "    [256, 3, -1],\n",
    "    [256, 3, -1],\n",
    "    [256, 3, -1],\n",
    "    [256, 3, 3],\n",
    "]\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    vocab_size+1,\n",
    "    embedding_size,\n",
    "    input_length=input_size,\n",
    "    weights=[embedding_weights]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional parameters defined\n",
    "\n",
    "fully_connected_layers = [1024, 1024]\n",
    "num_of_classes = 4\n",
    "dropout_p = 0.5\n",
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1014)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1014, 69)          4830      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1008, 256)         123904    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1008, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 336, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 330, 256)          459008    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 330, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 110, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 108, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 108, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 106, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 106, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 104, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 104, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 102, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 102, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 34, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8704)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 34820     \n",
      "=================================================================\n",
      "Total params: 1,410,018\n",
      "Trainable params: 1,410,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model:\n",
    "\n",
    "# Input layer, shape of (?, 1011)\n",
    "inputs = Input(shape=(input_size,), name='input', dtype='int64')\n",
    "\n",
    "# Embedding layer\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "# Convolutional Layer\n",
    "for filter_num, filter_size, pooling_size in conv_layers:\n",
    "    x = Conv1D(filter_num, filter_size)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if pooling_size != -1:\n",
    "        x = MaxPooling1D(pool_size=pooling_size)(x)\n",
    "\n",
    "x = Flatten()(x) # results in a (None, 8704) shape\n",
    "\n",
    "# Output layer\n",
    "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 - 12s - loss: 1.3857 - accuracy: 0.2580 - val_loss: 1.3602 - val_accuracy: 0.4400\n",
      "Epoch 2/10\n",
      "8/8 - 10s - loss: 1.3699 - accuracy: 0.3240 - val_loss: 1.3963 - val_accuracy: 0.2400\n",
      "Epoch 3/10\n",
      "8/8 - 10s - loss: 1.3738 - accuracy: 0.3050 - val_loss: 1.3522 - val_accuracy: 0.3400\n",
      "Epoch 4/10\n",
      "8/8 - 10s - loss: 1.3462 - accuracy: 0.3460 - val_loss: 1.2914 - val_accuracy: 0.4400\n",
      "Epoch 5/10\n",
      "8/8 - 10s - loss: 1.3229 - accuracy: 0.3530 - val_loss: 1.3357 - val_accuracy: 0.3400\n",
      "Epoch 6/10\n",
      "8/8 - 10s - loss: 1.2693 - accuracy: 0.4310 - val_loss: 1.2960 - val_accuracy: 0.4400\n",
      "Epoch 7/10\n",
      "8/8 - 10s - loss: 1.1909 - accuracy: 0.4610 - val_loss: 1.4851 - val_accuracy: 0.3900\n",
      "Epoch 8/10\n",
      "8/8 - 10s - loss: 1.0020 - accuracy: 0.5750 - val_loss: 1.5096 - val_accuracy: 0.3600\n",
      "Epoch 9/10\n",
      "8/8 - 10s - loss: 0.6532 - accuracy: 0.7450 - val_loss: 1.7948 - val_accuracy: 0.3400\n",
      "Epoch 10/10\n",
      "8/8 - 10s - loss: 0.3669 - accuracy: 0.8660 - val_loss: 2.6382 - val_accuracy: 0.3400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c509794460>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle\n",
    "indices = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_train = train_data[indices][:1000]\n",
    "y_train = train_classes[indices][:1000]\n",
    "\n",
    "x_test = test_data[:100]\n",
    "y_test = test_classes[:100]\n",
    "\n",
    "# Training\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1014,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[101].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8, 15, 13, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(test_data[101], (1, 1014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18573591, 0.5521907 , 0.17353961, 0.08853371]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.reshape(test_data[105], (1, 1014)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 15, 13, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\PYTHON\\WorkNotes\\charCNN\\charCNN_preproc.ipynb Cell 43'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/PYTHON/WorkNotes/charCNN/charCNN_preproc.ipynb#ch0000042?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mget_layer(\u001b[39m'\u001b[39;49m\u001b[39membedding\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mpredict(test_data[\u001b[39m101\u001b[39m], (\u001b[39m1\u001b[39m, \u001b[39m1014\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model.get_layer('embedding').predict(test_data[101], (1, 1014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 69)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('embedding').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be43905bfd324f5534f32fa5fd84a844ed612601ac6ee2d3fc95da0a82465c53"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('microbots')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
